---
layout: post
published: true
mathjax: false
featured: false
comments: false
title: Keras
categories:
  - tensorflow
---
## GTSRB with Keras

In my last blog post I described how I built a model for traffic sign recognition with tensorflow. The data set contains of 43 different German traffic signs for example:

![Screenshot from 2018-07-27 12-22-22.png]({{site.baseurl}}/images/Screenshot%20from%202018-07-27%2012-22-22.png)

The training set contains approximately 39.000 images and the test set around 12.000 images.

To use the network in a browser application I wanted to "deploy" it via tensorflow.js! ([https://www.youtube.com/watch?v=656l4IfhM10](https://www.youtube.com/watch?v=656l4IfhM10))

The easiest way to use a pretrained model in tensorflow.js seems to be by using Keras (`pip install keras`). Keras is a high-level API which can use multiple backends with tensorflow and tensorflow.js being part of them.

Because I still don't have a GPU I am going to try to work with colab.research.google.com which provides the same convenience as the Kaggle notebooks coming with access to one GPU.

Source: [http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset](http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset)

Inspirational blog entry: [keras tutorial](https://chsasank.github.io/keras-tutorial.html)

## Loading the data

```python
import requests
import os.path
import zipfile
import os


# Load the dataset
train_data_url = 'http://benchmark.ini.rub.de/Dataset/GTSRB-Training_fixed.zip'
test_data_url = 'http://benchmark.ini.rub.de/Dataset/GTSRB_Online-Test-Images.zip'

def maybe_download_file(url):
  # the name of the file
  local_filename = url.split('/')[-1]
  if os.path.isfile(local_filename):
    print('File already exists')
    return local_filename
  # NOTE the stream=True parameter
  r = requests.get(url, stream=True)
  with open(local_filename, 'wb') as f:
      for chunk in r.iter_content(chunk_size=1024): 
          if chunk: # filter out keep-alive new chunks
              f.write(chunk)
              #f.flush() commented by recommendation from J.F.Sebastian
  return local_filename
  

def extract_archive(file_name, target_dir):
  # only extract the zip if the target_dir doesn't exist
  if os.path.isfile(target_dir):
      print('Dir already exists')
      return target_dir
  with open(file_name, 'rb') as f:
      zf = zipfile.ZipFile(f)
      zf.extractall(target_dir)
  return target_dir

  
file_path = maybe_download_file(test_data_url)
extract_archive(file_path, 'test_data')

file_path = maybe_download_file(train_data_url)
extract_archive(file_path, 'train_data')

```


The code downloads the training and testing data sets and extracts them.

The following lists the files:

```python

def list_files(startpath, depth=3):
  for root, dirs, files in os.walk(startpath):
      level = root.replace(startpath, '').count(os.sep)
      if level <= depth:
        indent = ' ' * 4 * (level)
        print('{}{}/'.format(indent, os.path.basename(root)))
        subindent = ' ' * 4 * (level + 1)
        for f in files:
            print('{}{}'.format(subindent, f))
          

list_files('.', depth=3)
```

**Install requirements:**

```
!pip install keras
!pip install scikit-image
```

## Preprocessing and the images

```python

import numpy as np
import os
import glob

from skimage import io, transform, exposure, color

NUM_CLASSES = 43
IMG_SIZE = 32


def preprocess_img(img):
    # Histogram normalization in v channel
    hsv = color.rgb2hsv(img)
    hsv[:, :, 2] = exposure.equalize_hist(hsv[:, :, 2])
    img = color.hsv2rgb(hsv)

    # central square crop
    min_side = min(img.shape[:-1])
    centre = img.shape[0] // 2, img.shape[1] // 2
    img = img[centre[0] - min_side // 2:centre[0] + min_side // 2,
              centre[1] - min_side // 2:centre[1] + min_side // 2,
              :]

    # rescale to standard size
    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))

    # roll color axis to axis 0
    img = np.rollaxis(img, -1)

    return img


def get_class(img_path):
    return int(img_path.split('/')[-2])

root_dir = 'train_data/GTSRB/Training/'
imgs = []
labels = []

all_img_paths = glob.glob(os.path.join(root_dir, '*/*.ppm'))
np.random.shuffle(all_img_paths)

i = 0
for img_path in all_img_paths:
    if i%1000 == 0:
        print("{}".format(i))
    i += 1
    img = preprocess_img(io.imread(img_path))
    label = get_class(img_path)
    imgs.append(img)
    labels.append(label)

X = np.array(imgs, dtype='float32')
# Make one hot targets
Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]

```


## A glimpse into the data set

```python
%matplotlib inline

# Visualize some images
n_images_per_class = 3
  
import random
import numpy as np
import matplotlib.pyplot as plt

w=32
h=32

fig=plt.figure(figsize=(10, 80))

columns = n_images_per_class
rows = NUM_CLASSES

print(X.shape)

for i in range(1, columns*rows +1):
  img = imgs[random.randint(0, 26640)]
  img = np.rollaxis(img, -1)
  img = np.rollaxis(img, -1)
  fig.add_subplot(rows, columns, i)
  plt.imshow(img)
    
plt.show()
```

![Screenshot from 2018-07-28 20-29-26.png]({{site.baseurl}}/images/Screenshot from 2018-07-28 20-29-26.png)












 








